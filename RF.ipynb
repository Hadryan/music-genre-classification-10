{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RF.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhsangwan/music-genre-classification/blob/main/RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdrsZ6HFd92c"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmxP_zWPeSj9"
      },
      "source": [
        "%cd drive/MyDrive/IDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubbO93Iselw6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import plotly.figure_factory as ff\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vxReuRNeaTJ"
      },
      "source": [
        "data = pd.read_csv(\"music-genre-classification/data/merged_data.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx41TFJ-NCt0"
      },
      "source": [
        "data= data.drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn4Q3XqPoLVI"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duZX9RN1NYM_"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM4nPa7Aexkt"
      },
      "source": [
        "#explore data\n",
        "print(f'Number of variables - {data.shape[1]}\\n')\n",
        "print(f'Data Types for each variable - \\n{data.dtypes}\\n')\n",
        "print(f'Number of variables for each data type - \\n{data.dtypes.value_counts()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMvcRkVFfFA4"
      },
      "source": [
        "#search missing data\n",
        "#Counting Null values for each column\n",
        "null_count = data.isnull().sum()\n",
        "null_count = null_count[null_count>0]\n",
        "\n",
        "#Printing null counts for columns that have null count >0\n",
        "print(f'Null count for Columns - \\n{null_count}\\n\\n')\n",
        "\n",
        "#Printing % of null counts for columns that have null count>0\n",
        "for column, null_co in null_count.iteritems():\n",
        "    print(f'Percentage of missing values for Column {column} - {null_co*100/data.shape[0]:.2f} %')\n",
        "    if (null_co*100/data.shape[0]) > 0:\n",
        "      col = column \n",
        "      data[data.isnull().any(axis=1)][[col]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq2ddqMyflEc"
      },
      "source": [
        "data = data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXbEbvJbfqSU"
      },
      "source": [
        "#Counting Null values for each column\n",
        "null_count = data.isnull().sum()\n",
        "null_count = null_count[null_count>0]\n",
        "print(null_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcO567fofvdv"
      },
      "source": [
        "#Checking boolean False counts for each column, an empty/blank string or integer 0 will result in a False value\n",
        "#for boolean type\n",
        "bool_counts = data.astype(bool).sum(axis=0)\n",
        "for col, val in bool_counts.iteritems():\n",
        "    print(f'{col} Percentage Boolean False Counts {(data.shape[0]-val)*100/data.shape[0]:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULVSeNHUf50u"
      },
      "source": [
        "sns.countplot(x = 'genre', data = data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYqccOc9n-8z"
      },
      "source": [
        "Partition data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv7WXRIUmKdY"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4WsRORPyS2F"
      },
      "source": [
        "data_new = data.drop(columns=['genre','title', 'track_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtaUn82EKh6c"
      },
      "source": [
        "#classification data splitting \n",
        "X_train,X_test, Y_train, Y_test = train_test_split(data_new.iloc[:,:], data['genre'], test_size = 0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyY3ap2QK_4r"
      },
      "source": [
        "print(X_train.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-jawelNLufd"
      },
      "source": [
        "# Explore test set\n",
        "print(X_test.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SVLEBoRLRrt"
      },
      "source": [
        "**Standardize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "argX11ioLXuW"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXhx5PJTysp5"
      },
      "source": [
        "#SelectKBest(f_classif, k=20).fit_transform(X_train, Y_train)\n",
        "f_classif(X_train_scaled, Y_train)\n",
        "np.mean(f_classif(X_train_scaled, Y_train)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "527l_6mx6BPx"
      },
      "source": [
        "**Initial random forest model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og5QDXhXNMD9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf=RandomForestClassifier(n_estimators=200)\n",
        "clf.fit(X_train_scaled,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14OAyYdDNvLC"
      },
      "source": [
        "Y_pred=clf.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZgDkT4UNxrN"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDkHw0ZVBHiw"
      },
      "source": [
        "**Cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTSqCm0u0ScI"
      },
      "source": [
        "cv_scores_dict = {}\n",
        "criterion_list = ['gini', 'entropy']\n",
        "for n_estimators in [200, 300,400,500]:\n",
        "    cv_scores = []\n",
        "    for criterion in criterion_list:    \n",
        "        RM_model = RandomForestClassifier(n_estimators = n_estimators, criterion=criterion,random_state=1)\n",
        "        cv_scores.append(np.mean(cross_val_score(RM_model, X_train_scaled, Y_train, cv=10,n_jobs=-1)))\n",
        "    max_cv_score = max(cv_scores)\n",
        "    max_criterion = criterion_list[cv_scores.index(max_cv_score)]\n",
        "    cv_scores_dict[n_estimators] = {'criterion': max_criterion, 'cv_score': max_cv_score, 'n_estimators': n_estimators}\n",
        "print(cv_scores_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7nFQNLH07R2"
      },
      "source": [
        "**Random forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDezggWr2Gji"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf=RandomForestClassifier(n_estimators=400,criterion='gini' ,random_state=1)\n",
        "clf.fit(X_train_scaled,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANfLfUt2KkO"
      },
      "source": [
        "Y_pred=clf.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lui_xZZI2YsR"
      },
      "source": [
        "conf_matrix = metrics.confusion_matrix(Y_test,Y_pred)\n",
        "sns.heatmap(conf_matrix, annot = True, fmt = \".2f\", square = True, cmap = plt.cm.Blues)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion matrix')\n",
        "plt.tight_layout()\n",
        "print(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwOFa0vB2fSU"
      },
      "source": [
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "error = 1 - accuracy\n",
        "precision = metrics.precision_score(Y_test, Y_pred, average = None)\n",
        "recall = metrics.recall_score(Y_test, Y_pred, average = None)\n",
        "F1_score = metrics.f1_score(Y_test, Y_pred, average = None)\n",
        "print(\"Accuracy\",accuracy,\"\\nError\", error,\"\\nPrecision\", precision,\"\\nRecall\", recall,\"\\nF1_score\", F1_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pVOpt6q_jaS"
      },
      "source": [
        "**Parameter variations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdWg76Vd-IWb"
      },
      "source": [
        "sample_size = [1000,2000,3000,4000,5000,6000]\n",
        "accuracy=[]\n",
        "for i in sample_size:\n",
        "  clf=RandomForestClassifier(n_estimators=400,criterion='gini' ,random_state=1,max_samples=i)\n",
        "  clf.fit(X_train_scaled,Y_train)\n",
        "  Y_pred=clf.predict(X_test_scaled)\n",
        "  accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
        "  print(\"Sample size: \",i,\" Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
        "\n",
        "plt.plot(sample_size, accuracy)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EB4UW7UDy9H"
      },
      "source": [
        "max_leaf_nodes = [200,400,600,800,1000,1200]\n",
        "accuracy=[]\n",
        "for i in max_leaf_nodes:\n",
        "  clf=RandomForestClassifier(n_estimators=400,criterion='gini' ,random_state=1,max_leaf_nodes=i)\n",
        "  clf.fit(X_train_scaled,Y_train)\n",
        "  Y_pred=clf.predict(X_test_scaled)\n",
        "  accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
        "  print(\"Max Leaf Node: \",i,\" Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
        "\n",
        "plt.plot(max_leaf_nodes, accuracy)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoYgYRPPGjC6"
      },
      "source": [
        "max_features = [10,20,30,40,50,60,70]\n",
        "accuracy=[]\n",
        "for i in max_features:\n",
        "  clf=RandomForestClassifier(n_estimators=400,criterion='gini' ,random_state=1,max_features=i)\n",
        "  clf.fit(X_train_scaled,Y_train)\n",
        "  Y_pred=clf.predict(X_test_scaled)\n",
        "  accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
        "  print(\"Max Features: \",i,\" Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
        "\n",
        "plt.plot(max_features, accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwIwn6WH2pKC"
      },
      "source": [
        "**Top Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuMYv61l2j1O"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Build a forest and compute the impurity-based feature importances\n",
        "forest = clf=RandomForestClassifier(n_estimators=400,criterion='gini',random_state=1)\n",
        "\n",
        "forest.fit(X_train_scaled, Y_train)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X_train_scaled.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train_scaled.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train_scaled.shape[1]), indices)\n",
        "plt.xlim([-1, X_train_scaled.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}